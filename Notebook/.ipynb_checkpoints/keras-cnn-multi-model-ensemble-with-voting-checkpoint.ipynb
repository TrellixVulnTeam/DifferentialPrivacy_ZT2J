{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam # I believe this is better optimizer for our case\n",
    "from keras.preprocessing.image import ImageDataGenerator # to augmenting our images for increasing accuracy\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split # to split our train data into train and validation sets\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "np.random.seed(13) # My lucky number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "030b1ebf761aa450ce18b253813433ca5293c2fc"
   },
   "outputs": [],
   "source": [
    "num_classes = 10 # We have 10 digits to identify\n",
    "batch_size = 128 # Handle 128 pictures at each round\n",
    "epochs = 700 \n",
    "img_rows, img_cols = 28, 28 # Image dimensions 28 pixels in height&width\n",
    "input_shape = (img_rows, img_cols,1) # We'll use this while building layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc20a3a5e6d491e98be7d0ff3aaa6eec7bdc123b"
   },
   "outputs": [],
   "source": [
    "# Load some date to rock'n roll\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23e65adaf0ef381576c5597aebb6ce5dcc466174"
   },
   "outputs": [],
   "source": [
    "# Drop the label from the data and move it to real label part\n",
    "y_train = train[\"label\"]\n",
    "x_train = train.drop(labels = [\"label\"],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc3b21df164c213db201b317ba453c8914dd2200"
   },
   "outputs": [],
   "source": [
    "# Normalize both sets\n",
    "x_train /= 255\n",
    "test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "922cb2c73388a6ec4b368b032f133b2c4c9783c6"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape[0], 'train samples')\n",
    "print(test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ac625840bb33a39580405985955d9076c003d3c"
   },
   "outputs": [],
   "source": [
    "# Images should be in shape of height,width and color channel so it will be 28x28x1\n",
    "x_train = x_train.values.reshape(-1,img_rows,img_cols,1).astype('float32')\n",
    "test = test.values.reshape(-1,img_rows,img_cols,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "057065fd2bf1e11bdb9885b746c27452ee21505c"
   },
   "outputs": [],
   "source": [
    "# Class vectors needs to be binary so we use \"to_catogorical\" function of keras utilities for one-hot-encoding\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "412ce7ad208189b6f5ff03837f22358b683971c8"
   },
   "outputs": [],
   "source": [
    "# Lets split our train set into train and validation test sets with my lucky number 13 :)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e271e0d37535c7c401a873578ad3dd19b51b133"
   },
   "outputs": [],
   "source": [
    "def model_cnn(input_shape=input_shape, num_classes=num_classes):   \n",
    "    model = Sequential()\n",
    "\n",
    "    # Add convolutional layer consisting of 32 filters and shape of 3x3 with ReLU activation\n",
    "    # We want to preserve more information for following layers so we use padding\n",
    "    # 'Same' padding tries to pad evenly left and right, \n",
    "    # but if the amount of columns to be added is odd, it will add the extra column to the right\n",
    "    model.add(Conv2D(32, kernel_size = (3,3), activation='relu', input_shape = input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, kernel_size = (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Add convolutional layer consisting of 32 filters and shape of 5x5 with ReLU activation\n",
    "    # We give strides=2 for space between each sample on the pixel grid\n",
    "    model.add(Conv2D(32, kernel_size = (5,5), strides=2, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # Dropping %40 of neurons\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size = (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = (5,5), strides=2, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # To be able to merge into fully connected layer we have to flatten\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    # Lets add softmax activated neurons as much as number of classes\n",
    "    model.add(Dense(num_classes, activation = \"softmax\"))\n",
    "    # Compile the model with loss and metrics\n",
    "    model.compile(optimizer =  Adam() , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3b33a030f086dcc7469773c0482b1fee0ceccd8"
   },
   "outputs": [],
   "source": [
    "def LeNet5(input_shape=input_shape,num_classes=num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape, padding=\"same\"))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
    "    model.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "    model.add(Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer =  Adam() , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02093afb55f3706cd0cee60ae934b68ccd5bd1f9"
   },
   "outputs": [],
   "source": [
    "print(\"My Custom CNN Network:\")\n",
    "plot_model(model_cnn(), to_file='custom-cnn.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b697658f251681da1aac55d9261b118be7d301b6"
   },
   "source": [
    "<img src=\"custom-cnn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02093afb55f3706cd0cee60ae934b68ccd5bd1f9"
   },
   "outputs": [],
   "source": [
    "print(\"Master Yann LeCun's LeNet-5 Network:\")\n",
    "plot_model(LeNet5(), to_file='lenet-5.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58ae6f476c947df6e94bdce5ef35ba65b72e278a"
   },
   "source": [
    "<img src=\"lenet-5.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9a562361c9a42940bb22e9e41f3889c011f61f2"
   },
   "outputs": [],
   "source": [
    "model = []\n",
    "model.append(model_cnn())\n",
    "model.append(LeNet5())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b5468b524407441d9731b87e97bb010b7cded69"
   },
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation more detail: https://keras.io/preprocessing/image/\n",
    "datagen = ImageDataGenerator(rotation_range=10, zoom_range = 0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a6a4c747aac8cb06afa5f8be4f2c344600b12c46",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start multiple model training with the batch size\n",
    "models = []\n",
    "for i in range(len(model)):\n",
    "    model[i].fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                                        epochs = epochs, steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                                        validation_data = (x_test,y_test), \n",
    "                                        callbacks=[ReduceLROnPlateau(monitor='loss', patience=3, factor=0.1)], \n",
    "                                        verbose=2)\n",
    "    models.append(model[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b6fb41e9cc272eecab5b9a2c3394ef1aeb3ad09"
   },
   "outputs": [],
   "source": [
    "# Predict labels with models\n",
    "labels = []\n",
    "for m in models:\n",
    "    predicts = np.argmax(m.predict(test), axis=1)\n",
    "    labels.append(predicts)\n",
    "    \n",
    "# Ensemble with voting\n",
    "labels = np.array(labels)\n",
    "labels = np.transpose(labels, (1, 0))\n",
    "labels = scipy.stats.mode(labels, axis=-1)[0]\n",
    "labels = np.squeeze(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3505412d1bd1dc69df81edf60314e7bbbc266f39"
   },
   "outputs": [],
   "source": [
    "# Dump predictions into submission file\n",
    "pd.DataFrame({'ImageId' : np.arange(1, predicts.shape[0] + 1), 'Label' : labels }).to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
